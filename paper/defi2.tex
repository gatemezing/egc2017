\documentclass[a4paper,pagenum,english]{rnti}
\usepackage{graphicx}
\usepackage{listings}

\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{url}


\usepackage{xcolor}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}


\titrecourt{GeoCarteApp: A generic and personalized tool for the visualization of geospatial data}

\nomcourt{I. Bakerally et al.}


\titre{GeoCarteApp: A generic and personalized tool for the visualization of geospatial data}

\auteur{Noorani Bakerally\affil{1},
        Ghislain Atemezing\affil{2}\\
        Antoine Zimmermann\affil{1},
        Olivier Boissier\affil{1}}

\affiliation{
    \affil{1}Univ Lyon, MINES Saint-\'Etienne, CNRS, Laboratoire Hubert Curien UMR 5516, \\F-42023 Saint-\'Etienne, France\\
          \{prenom.nom\}@emse.fr\\
    %
    \affil{2}Mondeca, \\ 35 boulevard Strasbourg, Paris, France\\
          ghislain.atemezing@mondeca.com\\
          %\http{http://www.mondeca.com}
 }

\resume{GeoSpatial data is becoming more and more important in numerous domains. A common usage of geospatial data is to visualize it on a map. For a map application to directly consume geosptial data, the data has to follow some standards or best practices such as GeoSPARQL or WSG84 vocabulary. However, there are still many datasets provided by organizations or open data portals which partly conform or do not conform at all to these standards and best practices. As a result, map application cannot directly consume them for visualization. Within many organisations, domain experts may need to visualize geospatial data from numerous heterogenous sources on a single map for analysis. As such, there is a need for a tool which consume different types of geospatial data, whether standardized, partially standard or heterogeneous to produce a map visualization. In this paper, we provide the description such a tool, GeoCarteApp, which can generate a default visualization of geospatial data irrespective of the model or format of the data. Moreover, we explain how further configurations can be fed input to produce personalized visualisation. Finally, we describe its usefulness in relation to the tree's dataset provided for Défi 2.}

%\summary{}

\begin{document}
\section{Introduction}
Currently, much data is available from open data portals and organizations. These data are encoded in different formats and based on different data models. Much of these data are geospatial data about different themes such as transportation, public services and others. Many standards and best practices such as GeoSPARQL~[\cite{battle2011geosparql}] or WSG84 vocabulary~[\cite{brickleybasic}] have been defined to facilitate geospatial data integration. By following these standards and best practices, geospatial applications such as map application can directly consume the data. As of now, map applications and APIs can directly consume data in standard format such GeoJSON, KML, ShapeFile and some others. For example, using Google Maps, one may drag and drop a GeoJSON data the map and directly visualize it. However, there are still many datasets provided by organizations and open data portals which partly conform or do not conform at all to these geospatial standards and best practices. As of now, datasets from open data portals are still mostly in heterogeneous format such as CSV, JSON and others. For example, simplemaps\footnote{\url{http://simplemaps.com}} provide a free dataset\footnote{\url{http://simplemaps.com/resources/world-cities-data}} about world cities together with their geospatial information in CSV. Such a dataset cannot be cannot be directly consumed for visualization purposes. Moreover, LinkedGeoData~\cite{stadler2012linkedgeodata} is a rich source of geospatial data which provides information collected by OpenStreetMap project and makes it available as RDF via their SPARQL endpoint \footnote{\url{http://linkedgeodata.org/sparql}} and RDF datasets. SPARQL queries can be written to obtain useful information from this source however the SPARQL results cannot be directly consume by map APIs for visualization. Same is the case for GeoNames\footnote{\url{http://www.geonames.org/}} or DBpedia\footnote{\url{http://wiki.dbpedia.org/}} and other rich sources of geospatial data. To allow the map APIs to consume data from heterogeneous sources, developers have to programmatically parse the data and make it conform to the structure required by the map application or API. This task is time consuming and also requires skills and competency which may not be available by parties, such as domain experts, interested in visualizing geospatial data.

In addition, even though map APIs like Google Map have the GeoJSON Drag and Drop\footnote{\url{https://developers.google.com/maps/documentation/javascript/examples/layer-data-dragndrop}} to directly consume GeoJSON, it does not create unique colors for each layers from different sources. As a result, all marker and vector layers have the same color respectively which makes it difficult to analyse the visualization. Moreover, in GeoJSON, a features can have a number of properties. The default drag and drop feature does not consider these properties in the visualization. These properties could have been used to in popups to provide some information when clicking on the layers. To customize the colors and popups for description, the API has to be programmatically exploited.

To complement all these issues, we propose a tool, GeoCartApp. The tool can consume geospatial data from RDF, SPARQL results and GeoJSON and produce default visualization. In the default visualization, the tool exploits data about the geospatial object to generate default description and filters which can be used for search purposes. Moreover, the tool provide a means to customize the visualization through configuration files to produce highly personalized visualizations seamlessly. In the rest of this paper, (1) we provide a description of the generic approach used by GeoCartApp to generate a default visualization of geospatial data in Section \ref{section:generic}; (2) we explain how this default visualization can be customized through configuration files to allow users to personalize the visualization according to their own preferences in Section \ref{section:customisation}; (3) we consider the use of GeoCartApp in the case of the dataset provided for Defi 2 in Section \ref{section:application_grenoble}

\section{Visualizing GeoSpatial Data with GeoCartApp}\label{section:generic}
\begin{figure}
\includegraphics[scale=0.6]{img/generic_approach.pdf}
\caption{High-level view of GeoCartApp}
\label{fig:generic}
\end{figure}
Figure \ref{fig:generic} shows a high-level view of GeoCartApp. As it can be seen, GeoCartApp can consume data from three main sources namely RDF, SPARQL results and GeoJSON and produce a default visualization together with default filters for search purposes. As of now, the processor cannot consume data in other heterogeneous formats. But it can be further enhanced by using SPARQL Generate  \footnote{\url{http://ci.emse.fr/sparql-generate/}} which can produces RDF equivalent of data in formats like CSV, JSON and others. The, the RDF equivalents can then be directly input to the processor.

At the core of our tool is the processor which can process data from the three main sources and which can optionally take configuration files to produce personalized visualizations. In this section, we first provide a description of some the classes used by the processor. Then, we explain the generic approach used by the processor to generate the default visualization. Finally, we explain how the processor can consume configuration files to produce personalized visualizations. 

\subsection{Classes used by the Processor}
\begin{figure}
\center
\includegraphics[scale=0.5]{img/class_diagram.pdf}
\caption{Part of GeoCarteApp class diagram}
\label{fig:class_diagram}
\end{figure}
GeoCartApp is a web application written in JavaScript. It uses the JavaScript library Leaflet\footnote{\url{http://leafletjs.com/}}. The core of the application is a processor which uses the classes we defined and those defined in Leaflet. Part of the class diagram is shown in Figure \ref{fig:class_diagram}. In the class diagram, the class "Layer" and "LayerGroup" is defined within the Leaflet JavaScript Library.   

The processor can consume data from the three datasources. For each datasource, there is one DataItemGroup. For example, in Figure \ref{fig:sample_visu}, every item in the top-right table in Section 1 like "Secteurs" is an instance of DataItemGroup. A DataItemGroup contains one or more DataItems. A DataItem contains information about one item which is shown on the map. What is shown on the map is the Layer of the DataItem. Leaflet provides the LayerGroup class which can contains one or more Layers. On adding a LayerGroup to a map, all the Layers within it are also added. The DataItemGroup has a LayerGroup which contains all the Layer of its corresponding DataItems. When a DataItemGroup need to shown on the map, its LayerGroup, which contains all Layers of its DataItems, is added to the map. As a result, all the DataItems' Layers are also added to the Map.

\subsection{Description of the Generic Approach}
\begin{figure}
\center
\includegraphics[scale=0.5]{img/default_filter.png}
\caption{Default filters for trees}
\label{fig:default_filter}
\end{figure}

\begin{figure}
\center
\includegraphics[scale=0.5]{img/default_description.png}
\caption{Default description for a sector in Grenoble}
\label{fig:default_description}
\end{figure}
The processor can consume geospatial data from three datasources. As shown in Figure \ref{fig:class_diagram}, there is a specific class to process data for each of these datasources. A minimal configuration file is needed by the processor to generate a default visualization from one ore more datasources. Such a configuration will only describe the datasources, for RDFDataSource and GeoJSONDataSource, it  specifies the URL of the RDF and GeoJSON file. For SPARQLResultDataSource, the SPARQL endpoint URL, the query, the variable corresponding to the latitude and longitude are specified. As sample of such a minimal configuration is shown in \ref{listing:default_configuration}. As of now, from RDFDataSource and SPARQLDataSource, only MarkerDataItems can be created. For GeoJSONDataSource, both MarkerDataItems and VectorDataItems can be created.

The default visualization of RDF data is possible by using WGS84 vocabulary. This means that using the default configuration, only RDF dataset using the WGS84 vocabulary can be visualized. All subjects having the predicate geo:lat and geo:long is extracted where geo is a prefix related to an IRI\footnote{\url{http://www.w3.org/2003/01/geo/wgs84_pos#}}. For each of these subject, all its other predicates are also considered. For each subject, a MarkerDataItem is created. The MarkerDataItem has a minimum of two properties, the latitude and the longitude. Then for each subject, the MarkerDataItem takes all its properties and corresponding property value or values.
 
For a SPARQLDataSource, the processor queries the SPARQL endpoint with the query. For each solution in the SPARQL result, a MarkerDataItem is created. As shown in Listing \ref{listing:default_configuration}, for a SPARQLDataSource, the variable used as the latitude and longitude must be specified. For a particular solution, the MarkerDataItem takes all the variable as its properties and corresponding variable binding as its property value. 

GeoJSON can be directly consume by map APIs like Google Maps\footnote{\url{https://developers.google.com/maps/}} or MapBox\footnote{\url{https://www.mapbox.com}}. However, when consumed via the generic processor, default unique colors are applied to the rendered GeoJSON layers to ensure that it is distinguished among other map layers. This is particulary important if one is making a map mashup whereby data from numerous sources are bring on a single map.

For a GeoJSONDataSource, a Leaflet function is used to process the GeoJSON file. This function has callback which returns one feature and its corresponding created Layer. If the feature's geomety is a point, a MarkerDataItem is created else a VectorDataItem is created. In either case, the DataItem takes all the properties and corresponding property values for the feature.  

For all the three type of DataSources, a DataItemGroup is created which holds all the DataItems. Also, while creating DataItems for each DataSource, the processor collects the DataItem properties and for each property, it collects the values. Using this, the application can then provides a filtering mechanism for each DataItemGroup as shown in Figure \ref{fig:default_filter}, where for each property, a set property values is provided in a drop-down list. Property values can selected for the properties and the filter can be applied on the particular DataItemGroup. After applying the filters for a particular DataItemGroup, only those DataItem will be shown on the map which satisfy all the filters. As of now, a DataItem is shown only if its properties and property values satisfy all the filters, i.e. the filter expression is a logical AND of all the filters. This semantic can be further enhanced in future versions of the application where filter expression may be a logical OR or XOR of all filters.

The processor also generates a default description for each DataItem. The default description is simply a table having all property and property values, default description is binded to the Layer of the DataItem, on clicking on the Layer for that corresponding DataItem, a popup as shown in Figure\ref{fig:default_description} 
\begin{lstlisting}[language=json,firstnumber=1, caption={Sample default configuration file}\label{listing:default_configuration}]
{"FranceGeoNames": {
	"dataSource": {
	"type": "RDFDataSource",
	"url": "http://www.geonames.org/3017382/about.rdf"
	}
},"Ecoles Elementaires": {
	"dataSource": {
	"type": "GeoJSONDataSource",
	"url": "http://sig.grenoble.fr/opendata/Decoupage/json/DECOUPAGE_%C3%89L%C3%89MENTAIRES_EPSG4326.json"
	}
},"Arbres": {
	"latCol": "lat",
	"longCol": "long",
	"dataSource": {
	"type": "SPARQLDataSource",
	"url": "http://data.mondeca.com/egc2017/sparql",
	"query": "The SPARQL Query goes here"
}
}}
\end{lstlisting}
\subsection{Customisation/Configuration (source)}\label{section:customisation}
GeoCarteApp can provide a default visualization with default unique colors, filters and DataItem descriptions. But, the configuration can also be further customized to produce a personalized visualization. There are two types of configuration. They are:
\begin{enumerate}
\item Application configuration
\item Data configuration
\end{enumerate}
\subsubsection{Application Configuration}
The application configuration file is simple configuration which provides descriptions to bootstrap the map, for example, providing the latitude,longitude and zoom level for the initial view. As of now, these are the only simple configuration provided. We intend to extend these configuration to also include more complex configuration like specifying the map provider, i.e. whether to use Google Maps, Bing Maps\footnote{\url{https://www.bing.com/mapspreview}} or any other map providers. A sample configuration file can be found on Github\footnote{\url{https://github.com/noorbakerally/EGC2017ConfigurationFile/blob/master/app.conf}}.

\subsubsection{Data Configurations}
The datasource configuration overrides the default configuration. For example, when the datasource is an RDFDataSource, by the default, the processor considers all subjects having a latitude and longitude description following the WGS84 vocabulary. However, it is possible that the RDF dataset uses a different vocabulary for latitude and longitude. To ensure that the processor finds the latitude and longitude description, two additional properties \texttt{latitudeProperty} and \texttt{longitudeProperty} can be added to the \texttt{datasource} to specify the property used for latitude and longitude respectively. 

Moreover, if the datasource is a SPARQLResultDataSource, by default, the processor creates a unique DataItem for each solution. However, it is possible that a SPARQL result contains two different solutions which corresponds to a single subject. For example, this can arise if a single subject occurs in at least two different triples with the same predicates but different objects. If the default configuration is used, the processor will create a distinct DataItem for each solution. To prevent this, a further property \texttt{identifier} can be added to the \texttt{datasource} description to tell the processor which variable acts as the identifier. Finally, using the identifier, when the processor iterates on the SPARQL solutions, it creates a single DataItem for solutions having similar identifiers.

By default, the processor generates a default description for each DataItem. It is possible to configure it so that there is no description or a custom description. The custom description provided in the configuration will take the form of a string marked up with one or more properties. For example, suppose an object has three properties namely "code", "latitude" and "longitude" with property values 234, 45 and 5 respectively. A custom description can be of the form "The sector \{code\} has latitude \{latitude\} and longitude \{longitude\}". The processor will then replace the property value for each of the three properties and generate a description like "The sector 234 has latitude 45 and longitude 5". Escape characters can be used where \{ or \} must be part of the raw string.
Also, it is possible to generate derived properties for objects. For example, in the case of Grenoble data, it is known that a particular tree was planed in a particular year. It is possible to have a new property "age" and calculate the age of the tree. This new derived attribute can then be used both in DataItem's description and filters. Also, different icons and colors can be specified for DataItems' Layers. Furthermore, Layers can have different appearances like color, border color, inside color or icon based on the properties of their corresponding DataItem. For example, trees in different age intervals can have different icons.

It may happen that a particular a DataItemGroup's LayerGroup have thousands of Layers. Due to resource limitations, it may not be possible to show all the Layers on the map. For example, in the tree dataset of Defi 2 for EGC 2017, there are 10251 trees. Displaying all the trees may consume much resources. In this case, constraints can be introduced to limit the number of Layers being rendered. As of now, we consider only one constraint which is \texttt{contains}. This constraints places a dependency between two DataItemGroups. For example, suppose there two DataItemGroup, one related to Grenoble Sectors and one related to the tree RDF dataset. A \texttt{contains} constraint can be placed between on DataItems in the tree DataItemGroup and DataItems in Grenoble Sectors. As a result, layers for tree DataItems are shown in Grenoble Sectors' DataItems which are visible on the map.  

As shown in Figure \ref{fig:default_filter}, there is a label for each property and for each value. These labels are taken raw as they are from the DataSource. As it can be seen both in Figure \ref{fig:default_filter} and \ref{fig:default_description}, the labels for the property and values follows some database or arbitrary conventions. Configurations can be used to allow for more user-friendly labels both for property and property values. Furthermore, by default, all values for a particular property are considered in the Filters' section of the user interface. In the configuration, it can be explicitly stated which property or property values to include or exclude. This can be particulary useful to omit null values or blank strings in drop-down list for property values.

\subsection{GeoCarteApp: An Instantiation of the Generic Approach}
GeoCartApp is generic in the sense that different configuration files can be written to generate visualization for completely different datasources and personalized configurations. To show the genericity of the tool, we run the same application with two different configuration files at two different locations namely location1\footnote{\url{http://geocarteapp.kissr.com/grenoble/}} and location2\footnote{\url{http://geocarteapp.kissr.com/defi/}}. The two instances shows completely two different visualization. The two configuration file can be found at location1\footnote{\url{http://geocarteapp.kissr.com/conf/data1.conf}} and location2\footnote{\url{http://geocarteapp.kissr.com/conf/data2.conf}}. 

Figure \ref{fig:sample_visu} shows part of GeoCarteApp. The user interface can be divided into three sections. Sections 1 shows all the DataItemGroups; Section 2 shows the filters for a particular DataItemGroup and Section 3 shows the map which contains all the LayerGroups for the DataItemGroups on the map.

In the table of Section 1, for each DataItemGroup, there is the icon to represent it on the map. It also shows the number of DataItems in that DataItemGroup. The layerGroup for a dataItemGroup can be shown or hidden by toggling the checkbox. Finally, by pressing the button with the eye icon, the filters for that dataItemGroup is shown in Section 2. In Section 2, the properties for the DataItems in the DataItemGroup are shown. The property values are available in the drop-down list. Property values for properties can be chosen and the filter can be applied to show view dataItems having these property and property values.
 
\begin{figure}
\center
\includegraphics[scale=0.5]{img/sample_visu.pdf}
\caption{Sample screenshot of GeoCarteApp}
\label{fig:sample_visu}
\end{figure}

\section{Application to Grenoble Data}\label{section:application_grenoble}
We apply our generic approach to visualize geospatial data in the domain of environment, in particular to monitor trees in the city of Grenoble. To that purpose, we first convert the legacy datasets into the RDF model, based on a vocabulary. Then we enrich the dataset with relevant datasets according to our use cases, and then we show how our application can be used by domain experts. Finally, we provide some recommendations on the data.

\subsection{Transformation and Enrichment of Data}
In this section, we explain the transformation and enrichment of the dataset provided for Defi 2. 

\subsection{Transformation}
The original datasets for Defi 2 consisted of 3 datasets. They are:
\begin{itemize}
\item File1: X\textunderscore tree\textunderscore egc\textunderscore t2.csv
\item File2: X\textunderscore geoloc\textunderscore egc\textunderscore t2.csv
\item File3: Y\textunderscore tree\textunderscore egc\textunderscore t2.csv
\end{itemize}
File1 contains details and descriptions about all the trees, File2 contains the geospatial coordinate of each trees using in EPSG:3945 (RGF 93/CC45). File3 contains whether the tree has any defect and if yes, where the defect is located on the tree. First of all, to transform the data, we had to change the spatial reference system from EPSG:3945 to EPSG:4326 as we chose to use the geospatial WGS84 vocabulary.

To merge all the data together in a single dataset, we had to join the each tree based on the row number in the files. This is because only File2 has a column CODE. Other files do not have this column. This step was intuitive as all the three files have the same number of rows.

Then, we provided an a model. The model use for the conversion of the CSV data is based on 2 classes, 4 object properties and 25 datatypes\footnote{\url{https://goo.gl/FTFGbh}}. We use the lgdo:Tree\footnote{\url{http://linkedgeodata.org/ontology/}} to represent the main class. The class \textit{tonto:Sector} is a sublass of a topological entity \textit{topo:EntiteTopographique}\footnote{\url{http://data.ign.fr/def/topo#}}. 
\subsection{Enrichment}
We added information about allergy-inducing trees from Wikipedia. We used dataset from the Wikipedia Page\footnote{\url{https://fr.wikipedia.org/wiki/Liste_des_plantes_allergisantes}} and converted it in RDF to enrich the original dataset with information on allergy for the species of the trees found in Grenoble. 
\subsection{Use Cases}
In this section, we provide some use cases and shows how GeoCarteApp can be of help to domain experts in the case of Grenoble.

\subsubsection{Use Case 1}
Trees have to be maintained. In the dataset, each tree has a remark, which says whether the branches have to be cut or a particular maintenance which have to be performed on the tree. Using the filters, domain experts can view trees which have to be diagnosed in a particular year. Now, they may have to decide when exactly they can go to perform the maintenance on the tree. This decision can be dependent on several parameters. For example, they may want to know whether the tree is near a school so that the maintenance can be done outside school hours. Using the DataItemGroup "Ecole" and "Arbres", all trees which have to be diagnosed in a particular year and all trees which are near to a school can be seen. 

\subsubsection{Use Case 2}
There are trees whose allergy-inducing level is known. This allergy-inducing level is scaled from 0 to 5 (from low to high allergy-inducing level). Using the filters, it is possible to find all trees with a particular allergy-inducing level whose surrounding are highly frequented by people. Moreover, it may be important to find all trees having an allergy-inducing level level of 4 or 5 and which are near to a school or hospital.

%\subsection{Recommendation on the Data}
% in French, to be translated
%Les données de localisation proposées dans ce défi souffrent du manque des métadonnées nécessaires pour faciliter leur exploitation, au moins sur deux aspects importants: le type de coordonnées géographiques et la correspondance des (X,Y) par rapport aux latitudes et longitudes. Ces éléments sont fondamentaux pour faciliter la réutilisation des données géographiques, surtout en qui concerne le positionnement et la meilleure interprétation des objets contenus dans les données. Il a fallu déterminer par des scripts ad hoc que les données géographiques utilisaient du EPSG:3945 (RGF 93/CC45) en limitant aux systèmes de coordonnées utilisées en France. 
%De même, entre les différents fichiers il n?existe pas de relation ?explicite? permettant de les relier entre elles, comme les clés dans les bases de données. Ce manque d?information nécessite un travail supplémentaire pour l?utilisateur des données de faire une inférence basée sur le même nombre de lignes dans les différents fichiers pour faire une corrélation de similarité basée sur les lignes.
%Nous préconisons de mettre explicitation sur les métadonnées des informations de systèmes de coordonnées, ainsi que la mention de relations existantes entre les différents fichiers à exploiter par les utilisateurs. 
%- dataset to be structured as per an ontology decided by domain experts
%- we tried to propose an ontology, however, since we lack expertise, the ontology may be erroneous
%- provide a transformation for the data from the CSV to a dataset
%- mix file together, or put identifier in the separate files
%- 


\section{Conclusion and Perspectives}
More and more geospatial data is now available with the idea of open data. This can create interesting usage use cases for both normal citizens and organizations. Map mashups can be created and provided on the Web for day to day scenarios or for analysis by domain experts. However, there is a lack of tool for the on-the-fly consumption of geospatial data in any format for visualization purposes. To our knowledge, there is no proposed approach for directly consuming geospatial data for map visualization from any data format. To this end, we propose a generic approach which can work without any configurations. We also propose the ability to define customisations in a configuration file to produce highly personalized visualization and filtering. As a proof of concept, we provide a toy application on the Web which is though not optimized but is fully function. As of now, using the application may be complex for non-technical users. This is because configuration files needs to be hand written. As a perspective, we consider the possibility of having user interfaces to help non-technical users in automatically generating configurations. Moreover, the configurations is not yet fully finalized and it will be an opportunity to have a vocabulary for to concertize the configurations and enhance its usage by interested parties. Last but not least, our future work includes the extension of this approach to consider other data formats such CSV, JSON and others. 

\paragraph{Acknowledgements} This work has been done within the OpenSensingCity project, supported by ANR (Agence Nationale de la Recherche), Project ID: ANR-14-CE24-0029.

\bibliographystyle{rnti}
\bibliography{biblioaz}
\end{document}
